# -*- coding: utf-8 -*-
"""Baseline_TRANSFORMERS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yvblt3W2q5PNCoCwBXwTxU9TG9RbRGxH
"""

#Model Implementations:
import pickle
f1=open('bert.pickle','ab')
f2=open('electra.pickle','ab')
f3=open('Longformer.pickle','ab')
f4=open('roberta.pickle','ab')
f5=open('xlnet.pickle','ab')

#Read the data
#f6 = open('data.pkl','rb')
#data = pickle.load(f6)

#remove 0.5 label
#data = [x for x in data if x[-1]!=0.5]

"""#5 Baseline Transformer Models are demonstrated here:

- BERT
 - ELECTRA
 - Longformer
 - roBERTa
 - XLNet

 Our Dataset is utilised as an input into these 5 models for comparison against the novel method
"""

!pip install simpletransformers

!pip show simpletransformers

import torch
torch.__version__

"""#BERT"""

from simpletransformers.classification import ClassificationModel, ClassificationArgs
import pandas as pd
import logging



logging.basicConfig(level=logging.INFO)
transformers_logger = logging.getLogger("transformers")
transformers_logger.setLevel(logging.WARNING)

# Preparing train data
#train_data = data
data = [["a golden retriever is a dog",1],
              ["a cat is a dog",0]]*100
train_data=data
train_df = pd.DataFrame(train_data)
train_df.columns = ["text", "labels"]

# Preparing eval data
eval_data = data
eval_df = pd.DataFrame(eval_data)
eval_df.columns = ["text", "labels"]

# Optional model configuration
model_args = ClassificationArgs(num_train_epochs=4)

# Create a ClassificationModel
model_bert = ClassificationModel("bert", 
                                 "bert-base-uncased",
                                 use_cuda = False)
# Saving the model for important metrics
pickle.dump(model_bert,f1)

"""#ELECTRA"""

from simpletransformers.classification import ClassificationModel, ClassificationArgs
import pandas as pd
import logging



logging.basicConfig(level=logging.INFO)
transformers_logger = logging.getLogger("transformers")
transformers_logger.setLevel(logging.WARNING)

# Preparing train data
train_data = data

train_df = pd.DataFrame(train_data)
train_df.columns = ["text", "labels"]

# Preparing eval data
eval_data = data
eval_df = pd.DataFrame(eval_data)
eval_df.columns = ["text", "labels"]

# Optional model configuration
model_args = ClassificationArgs(num_train_epochs=4)

# Create a ClassificationModel
model_electra = ClassificationModel(
    "electra", "google/electra-base-discriminator",use_cuda=False
)
# Saving the model for important metrics
pickle.dump(model_electra,f2)

"""#Longformer"""

from simpletransformers.classification import ClassificationModel, ClassificationArgs
import pandas as pd
import logging



logging.basicConfig(level=logging.INFO)
transformers_logger = logging.getLogger("transformers")
transformers_logger.setLevel(logging.WARNING)

# Preparing train data
train_data = data

train_df = pd.DataFrame(train_data)
train_df.columns = ["text", "labels"]

# Preparing eval data
eval_data = data
eval_df = pd.DataFrame(eval_data)
eval_df.columns = ["text", "labels"]

# Optional model configuration
model_args = ClassificationArgs(num_train_epochs=4)

# Create a ClassificationModel
model_longformer = ClassificationModel(
    "longformer", "allenai/longformer-base-4096", use_cuda=True
)
# Saving the model for important metrics
pickle.dump(model_longformer,f3)

"""#roBERTa"""

from simpletransformers.classification import ClassificationModel, ClassificationArgs
import pandas as pd
import logging



logging.basicConfig(level=logging.INFO)
transformers_logger = logging.getLogger("transformers")
transformers_logger.setLevel(logging.WARNING)

# Preparing train data
train_data = data

train_df = pd.DataFrame(train_data)
train_df.columns = ["text", "labels"]

# Preparing eval data
eval_data = data
eval_df = pd.DataFrame(eval_data)
eval_df.columns = ["text", "labels"]

# Optional model configuration
model_args = ClassificationArgs(num_train_epochs=4)

# Create a ClassificationModel
model_roberta = ClassificationModel(
    "roberta", "roberta-base", use_cuda = True
)
# Saving the model for important metrics
pickle.dump(model_roberta,f4)

"""#XLNet"""

from simpletransformers.classification import ClassificationModel, ClassificationArgs
import pandas as pd
import logging



logging.basicConfig(level=logging.INFO)
transformers_logger = logging.getLogger("transformers")
transformers_logger.setLevel(logging.WARNING)

# Preparing train data
train_data = data

train_df = pd.DataFrame(train_data)
train_df.columns = ["text", "labels"]

# Preparing eval data
eval_data = data
eval_df = pd.DataFrame(eval_data)
eval_df.columns = ["text", "labels"]

# Optional model configuration
model_args = ClassificationArgs(num_train_epochs=4)

# Create a ClassificationModel
model_xlnet = ClassificationModel(
    "xlnet", "xlnet-base-cased", use_cuda=True
)
# Saving the model for important metrics
pickle.dump(model_xlnet,f5)

"""#Calculate Accuracy, Precision, Recall, f1-score, AUC-ROC, AUC-PR, Confusion Matrix"""

import sklearn

"""#Accuracy Scores for BERT"""

#BERT
#Training Model
model_bert.train_model(train_df)

result, model_outputs, wrong_predictions = model_bert.eval_model(eval_df)
sklearn.metrics.accuracy_score(result, model_outputs, normalize=True, sample_weight=None)
sklearn.metrics.precision_score(result, model_outputs, normalize=True, sample_weight=None)
sklearn.metrics.f1_score(result, model_outputs, normalize=True, sample_weight=None)
sklearn.metrics.roc_auc_score(result, model_outputs, normalize=True, sample_weight=None)
sklearn.metrics.confusion_matrix(result, model_outputs, normalize=True, sample_weight=None)

"""#Accuracy Scores for ELECTRA"""

#ELECTRA
#Training Model
model_electra.train_model(train_df)

result, model_outputs, wrong_predictions = model_electra.eval_model(eval_df)
sklearn.metrics.accuracy_score(result, model_outputs, normalize=True, sample_weight=None)
sklearn.metrics.precision_score(result, model_outputs, normalize=True, sample_weight=None)
sklearn.metrics.f1_score(result, model_outputs, normalize=True, sample_weight=None)
sklearn.metrics.roc_auc_score(result, model_outputs, normalize=True, sample_weight=None)
sklearn.metrics.confusion_matrix(result, model_outputs, normalize=True, sample_weight=None)

"""#Accuracy Scores for Longformer"""

#Longformer
#Training Model
model_longformer.train_model(train_df)

result, model_outputs, wrong_predictions = model_longformer.eval_model(eval_df)
sklearn.metrics.accuracy_score(result, model_outputs, normalize=True, sample_weight=None)
sklearn.metrics.precision_score(result, model_outputs, normalize=True, sample_weight=None)
sklearn.metrics.f1_score(result, model_outputs, normalize=True, sample_weight=None)
sklearn.metrics.roc_auc_score(result, model_outputs, normalize=True, sample_weight=None)
sklearn.metrics.confusion_matrix(result, model_outputs, normalize=True, sample_weight=None)

